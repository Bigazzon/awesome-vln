# Awesome Vision-and-Language Navigation

A curated list of research papers in Vision-and-Language Navigation (VLN). Link to the code and website if available is also present.

## Contributing

Please feel free to contact me via email (liudq@mail.ustc.edu.cn) or open an issue or submit a pull request.

To add a new paper via pull request:
1. Fork the repo, edit `README.md`.
1. Put the new paper at the correct chronological position as the following format: <br>
    ```
    1. **Paper Title** <br>
    *Author(s)* <br>
    Conference, Year. [[Paper]](link) [[Code]](link) [[Website]](link)
    ```
1. Send a pull request. Ideally, I will review the request within a week.

## Papers

1. **Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments** <br>
*Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko Sünderhauf, Ian Reid, Stephen Gould, Anton van den Hengel* <br>
CVPR, 2018. [[Paper]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Anderson_Vision-and-Language_Navigation_Interpreting_CVPR_2018_paper.pdf) [[Code]](https://github.com/peteanderson80/Matterport3DSimulator) [[Website]](https://bringmeaspoon.org)

1. **Look Before You Leap: Bridging Model-Free and Model-Based Reinforcement Learning for Planned-Ahead Vision-and-Language Navigation** <br>
*Xin Wang, Wenhan Xiong, Hongmin Wang, William Yang Wang* <br>
ECCV, 2018. [[Paper]](https://arxiv.org/pdf/1803.07729)

